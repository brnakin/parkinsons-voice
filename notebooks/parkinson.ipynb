{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parkinson's Disease Detection from Voice Data\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "**Objective**: Develop a classification model to predict whether a person has Parkinson's disease using vocal biomarkers extracted from sustained phonations. Early diagnosis may help patients get better care and treatment.\n",
    "\n",
    "**Dataset**: UCI Parkinson's Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Download the data with wget to raw_data folder\n",
    "\n",
    "!mkdir -p ../data/raw\n",
    "\n",
    "!wget -q https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/parkinsons.data -O ../data/raw/parkinsons.data\n",
    "!wget -q https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/parkinsons.names -O ../data/raw/parkinsons.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Environment setup\n",
    "# !conda env create -f env.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Command for activate environment\n",
    "# !conda activate university-machine-learning-project-parkinsons-voice-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project structure created\n",
      "=== PARKINSON'S DISEASE DETECTION PIPELINE ===\n",
      "Random state: 42\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Load data/parkinsons.data with correct headers\n",
    "# Setup: Import libraries and create organized folder structure\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.feature_selection import (\n",
    "    SelectKBest,\n",
    "    f_classif,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    balanced_accuracy_score,\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "\n",
    "# Create organized folder structure\n",
    "def create_project_structure():\n",
    "    \"\"\"Create clean, organized project structure\"\"\"\n",
    "    folders = [\n",
    "        \"../data/raw\",\n",
    "        \"../data/processed\",\n",
    "        \"../models\",\n",
    "        \"../results\",\n",
    "        \"../figures\",\n",
    "    ]\n",
    "\n",
    "    for folder in folders:\n",
    "        Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(\"Project structure created\")\n",
    "\n",
    "\n",
    "create_project_structure()\n",
    "\n",
    "# Global settings\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"=== PARKINSON'S DISEASE DETECTION PIPELINE ===\")\n",
    "print(f\"Random state: {RANDOM_STATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LOADING DATA ===\n",
      "Dataset shape: (195, 24)\n",
      "Missing values: 0\n",
      "Duplicates: 0\n",
      "\n",
      "Target distribution:\n",
      "  Healthy (0): 48 (24.6%)\n",
      "  Parkinson's (1): 147 (75.4%)\n"
     ]
    }
   ],
   "source": [
    "# 3.1-3.4: Load and analyze data\n",
    "# 3.1-3.4: Load and analyze data\n",
    "def load_and_analyze_data():\n",
    "    \"\"\"Load data and perform basic analysis\"\"\"\n",
    "    print(\"\\n=== LOADING DATA ===\")\n",
    "\n",
    "    # Load data\n",
    "    df = pd.read_csv(\"../data/raw/parkinsons.data\")\n",
    "\n",
    "    # Basic info\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "    print(f\"Duplicates: {df.duplicated().sum()}\")\n",
    "\n",
    "    # Target analysis\n",
    "    target_counts = df[\"status\"].value_counts()\n",
    "    print(f\"\\nTarget distribution:\")\n",
    "    print(f\"  Healthy (0): {target_counts[0]} ({target_counts[0]/len(df)*100:.1f}%)\")\n",
    "    print(\n",
    "        f\"  Parkinson's (1): {target_counts[1]} ({target_counts[1]/len(df)*100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "    # Save target distribution plot\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    target_counts.plot(kind=\"bar\", color=[\"lightblue\", \"lightcoral\"])\n",
    "    plt.title(\"Target Distribution\")\n",
    "    plt.xticks([0, 1], [\"Healthy\", \"Parkinson's\"], rotation=0)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.pie(\n",
    "        target_counts.values,\n",
    "        labels=[\"Healthy\", \"Parkinson's\"],\n",
    "        autopct=\"%1.1f%%\",\n",
    "        colors=[\"lightblue\", \"lightcoral\"],\n",
    "    )\n",
    "    plt.title(\"Target Proportions\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"../figures/target_distribution.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = load_and_analyze_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STATISTICAL ANALYSIS ===\n",
      "Top 10 significant features (FDR < 0.05):\n",
      "  PPE: p=1.59e-16, Cohen's d=1.447 (large)\n",
      "  spread1: p=1.59e-16, Cohen's d=1.581 (large)\n",
      "  MDVP:APQ: p=1.27e-11, Cohen's d=0.903 (large)\n",
      "  spread2: p=7.16e-11, Cohen's d=1.180 (large)\n",
      "  MDVP:Jitter(Abs): p=1.28e-09, Cohen's d=0.831 (large)\n",
      "  MDVP:PPQ: p=2.40e-09, Cohen's d=0.696 (medium)\n",
      "  MDVP:Shimmer(dB): p=3.14e-09, Cohen's d=0.865 (large)\n",
      "  MDVP:Shimmer: p=4.22e-09, Cohen's d=0.912 (large)\n",
      "  MDVP:Jitter(%): p=7.90e-09, Cohen's d=0.669 (medium)\n",
      "  Jitter:DDP: p=8.18e-09, Cohen's d=0.639 (medium)\n"
     ]
    }
   ],
   "source": [
    "# 3.5-3.8: Statistical analysis\n",
    "def statistical_analysis(df):\n",
    "    \"\"\"Perform statistical analysis and effect size calculations\"\"\"\n",
    "    print(\"\\n=== STATISTICAL ANALYSIS ===\")\n",
    "\n",
    "    feature_cols = [col for col in df.columns if col not in [\"name\", \"status\"]]\n",
    "    healthy = df[df[\"status\"] == 0]\n",
    "    parkinsons = df[df[\"status\"] == 1]\n",
    "\n",
    "    # Mann-Whitney U tests\n",
    "    results = []\n",
    "    for feature in feature_cols:\n",
    "        stat, p_val = mannwhitneyu(\n",
    "            healthy[feature], parkinsons[feature], alternative=\"two-sided\"\n",
    "        )\n",
    "\n",
    "        # Cohen's d\n",
    "        mean1, std1 = healthy[feature].mean(), healthy[feature].std()\n",
    "        mean2, std2 = parkinsons[feature].mean(), parkinsons[feature].std()\n",
    "        pooled_std = np.sqrt(\n",
    "            ((len(healthy) - 1) * std1**2 + (len(parkinsons) - 1) * std2**2)\n",
    "            / (len(healthy) + len(parkinsons) - 2)\n",
    "        )\n",
    "        cohens_d = (mean2 - mean1) / pooled_std\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"feature\": feature,\n",
    "                \"p_value\": p_val,\n",
    "                \"cohens_d\": cohens_d,\n",
    "                \"effect_size\": (\n",
    "                    \"large\"\n",
    "                    if abs(cohens_d) > 0.8\n",
    "                    else \"medium\" if abs(cohens_d) > 0.5 else \"small\"\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    results_df = pd.DataFrame(results).sort_values(\"p_value\")\n",
    "\n",
    "    # FDR correction\n",
    "    _, p_fdr, _, _ = multipletests(results_df[\"p_value\"], method=\"fdr_bh\")\n",
    "    results_df[\"p_fdr\"] = p_fdr\n",
    "\n",
    "    # Show top significant features\n",
    "    significant = results_df[results_df[\"p_fdr\"] < 0.05].head(10)\n",
    "    print(f\"Top 10 significant features (FDR < 0.05):\")\n",
    "    for _, row in significant.iterrows():\n",
    "        print(\n",
    "            f\"  {row['feature']}: p={row['p_value']:.2e}, Cohen's d={row['cohens_d']:.3f} ({row['effect_size']})\"\n",
    "        )\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "stats_results = statistical_analysis(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STATISTICAL POWER ANALYSIS ===\n",
      "Sample sizes: Healthy = 48, Parkinson's = 147, Total = 195\n",
      "\n",
      "Top 10 features by statistical power:\n",
      "  spread1: Power=1.000 (High), Cohen's d=1.581\n",
      "  PPE: Power=1.000 (High), Cohen's d=1.447\n",
      "  spread2: Power=1.000 (High), Cohen's d=1.180\n",
      "  MDVP:Fo(Hz): Power=1.000 (High), Cohen's d=0.959\n",
      "  MDVP:Flo(Hz): Power=1.000 (High), Cohen's d=0.949\n",
      "  MDVP:Shimmer: Power=1.000 (High), Cohen's d=0.912\n",
      "  MDVP:APQ: Power=1.000 (High), Cohen's d=0.903\n",
      "  HNR: Power=1.000 (High), Cohen's d=0.895\n",
      "  Shimmer:APQ5: Power=0.999 (High), Cohen's d=0.866\n",
      "  MDVP:Shimmer(dB): Power=0.999 (High), Cohen's d=0.865\n",
      "\n",
      "Power distribution:\n",
      "  High power (≥0.8): 20 features\n",
      "  Medium power (0.5-0.8): 2 features\n",
      "  Low power (<0.5): 0 features\n",
      "✓ Power analysis results saved\n"
     ]
    }
   ],
   "source": [
    "# 3.8: Statistical power analysis\n",
    "def statistical_power_analysis(stats_results, df):\n",
    "    \"\"\"Conduct post-hoc statistical power analysis using observed Cohen's d\"\"\"\n",
    "    print(\"\\n=== STATISTICAL POWER ANALYSIS ===\")\n",
    "\n",
    "    # Calculate statistical power for observed effect sizes\n",
    "    # Using conventional alpha = 0.05 and sample sizes\n",
    "    healthy_n = len(df[df[\"status\"] == 0])\n",
    "    parkinsons_n = len(df[df[\"status\"] == 1])\n",
    "    total_n = len(df)\n",
    "\n",
    "    print(\n",
    "        f\"Sample sizes: Healthy = {healthy_n}, Parkinson's = {parkinsons_n}, Total = {total_n}\"\n",
    "    )\n",
    "\n",
    "    # Calculate statistical power for Cohen's d effect sizes\n",
    "    # Power = 1 - β (where β is Type II error rate)\n",
    "    # Using approximation: Power ≈ Φ(|d|√(n/2) - z_α/2) where Φ is normal CDF\n",
    "\n",
    "    z_alpha_2 = 1.96  # Critical value for α/2 = 0.025\n",
    "\n",
    "    # Calculate effective sample size (harmonic mean for unequal groups)\n",
    "    n_effective = 2 * healthy_n * parkinsons_n / (healthy_n + parkinsons_n)\n",
    "\n",
    "    power_results = []\n",
    "    for _, row in stats_results.iterrows():\n",
    "        feature = row[\"feature\"]\n",
    "        cohens_d = abs(row[\"cohens_d\"])\n",
    "\n",
    "        # Power calculation using normal approximation\n",
    "        # Power ≈ Φ(|d|√(n_eff/2) - z_α/2)\n",
    "        z_score = cohens_d * np.sqrt(n_effective / 2) - z_alpha_2\n",
    "\n",
    "        # Use normal CDF to get power\n",
    "        from scipy.stats import norm\n",
    "\n",
    "        power = norm.cdf(z_score)\n",
    "\n",
    "        # Classify power levels\n",
    "        if power >= 0.8:\n",
    "            power_level = \"High\"\n",
    "        elif power >= 0.5:\n",
    "            power_level = \"Medium\"\n",
    "        else:\n",
    "            power_level = \"Low\"\n",
    "\n",
    "        power_results.append(\n",
    "            {\n",
    "                \"feature\": feature,\n",
    "                \"cohens_d\": cohens_d,\n",
    "                \"power\": power,\n",
    "                \"power_level\": power_level,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    power_df = pd.DataFrame(power_results).sort_values(\"power\", ascending=False)\n",
    "\n",
    "    # Display top features by power\n",
    "    print(f\"\\nTop 10 features by statistical power:\")\n",
    "    for _, row in power_df.head(10).iterrows():\n",
    "        print(\n",
    "            f\"  {row['feature']}: Power={row['power']:.3f} ({row['power_level']}), Cohen's d={row['cohens_d']:.3f}\"\n",
    "        )\n",
    "\n",
    "    # Summary statistics\n",
    "    high_power = len(power_df[power_df[\"power\"] >= 0.8])\n",
    "    medium_power = len(power_df[(power_df[\"power\"] >= 0.5) & (power_df[\"power\"] < 0.8)])\n",
    "    low_power = len(power_df[power_df[\"power\"] < 0.5])\n",
    "\n",
    "    print(f\"\\nPower distribution:\")\n",
    "    print(f\"  High power (≥0.8): {high_power} features\")\n",
    "    print(f\"  Medium power (0.5-0.8): {medium_power} features\")\n",
    "    print(f\"  Low power (<0.5): {low_power} features\")\n",
    "\n",
    "    # Save power analysis results\n",
    "    power_df.to_csv(\"../results/statistical_power_analysis.csv\", index=False)\n",
    "    print(\"✓ Power analysis results saved\")\n",
    "\n",
    "    return power_df\n",
    "\n",
    "\n",
    "power_results = statistical_power_analysis(stats_results, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== VISUALIZING KEY FEATURES ===\n",
      "✓ Saved distributions for 6 key features\n"
     ]
    }
   ],
   "source": [
    "# 3.9: Key feature visualization\n",
    "def visualize_key_features(df, stats_results):\n",
    "    \"\"\"Visualize distributions of top discriminative features\"\"\"\n",
    "    print(\"\\n=== VISUALIZING KEY FEATURES ===\")\n",
    "\n",
    "    # Select top 6 features by effect size\n",
    "    top_features = stats_results.nlargest(6, \"cohens_d\")[\"feature\"].tolist()\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i, feature in enumerate(top_features):\n",
    "        ax = axes[i]\n",
    "\n",
    "        healthy_data = df[df[\"status\"] == 0][feature]\n",
    "        parkinsons_data = df[df[\"status\"] == 1][feature]\n",
    "\n",
    "        ax.hist(\n",
    "            healthy_data,\n",
    "            bins=20,\n",
    "            alpha=0.6,\n",
    "            label=\"Healthy\",\n",
    "            color=\"lightblue\",\n",
    "            density=True,\n",
    "        )\n",
    "        ax.hist(\n",
    "            parkinsons_data,\n",
    "            bins=20,\n",
    "            alpha=0.6,\n",
    "            label=\"Parkinson's\",\n",
    "            color=\"lightcoral\",\n",
    "            density=True,\n",
    "        )\n",
    "\n",
    "        ax.set_title(f\"{feature}\")\n",
    "        ax.set_xlabel(\"Value\")\n",
    "        ax.set_ylabel(\"Density\")\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.suptitle(\"Key Discriminative Features\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        \"../figures/key_features_distributions.png\", dpi=150, bbox_inches=\"tight\"\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"✓ Saved distributions for {len(top_features)} key features\")\n",
    "\n",
    "\n",
    "visualize_key_features(df, stats_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CORRELATION ANALYSIS ===\n",
      "Top 15 target correlations:\n",
      "  spread1: 0.565\n",
      "  PPE: 0.531\n",
      "  spread2: 0.455\n",
      "  MDVP:Fo(Hz): -0.384\n",
      "  MDVP:Flo(Hz): -0.380\n",
      "  MDVP:Shimmer: 0.367\n",
      "  MDVP:APQ: 0.364\n",
      "  HNR: -0.362\n",
      "  Shimmer:APQ5: 0.351\n",
      "  MDVP:Shimmer(dB): 0.351\n",
      "  Shimmer:APQ3: 0.348\n",
      "  Shimmer:DDA: 0.348\n",
      "  D2: 0.340\n",
      "  MDVP:Jitter(Abs): 0.339\n",
      "  RPDE: 0.309\n"
     ]
    }
   ],
   "source": [
    "# 3.10: Correlation analysis\n",
    "def correlation_analysis(df):\n",
    "    \"\"\"Analyze feature correlations\"\"\"\n",
    "    print(\"\\n=== CORRELATION ANALYSIS ===\")\n",
    "\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    corr_matrix = df[numeric_cols].corr()\n",
    "\n",
    "    # Plot correlation heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    sns.heatmap(\n",
    "        corr_matrix,\n",
    "        mask=mask,\n",
    "        center=0,\n",
    "        cmap=\"RdBu_r\",\n",
    "        square=True,\n",
    "        cbar_kws={\"shrink\": 0.8},\n",
    "    )\n",
    "    plt.title(\"Feature Correlation Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"../figures/correlation_heatmap.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    # Target correlations\n",
    "    target_corr = (\n",
    "        corr_matrix[\"status\"].drop(\"status\").sort_values(key=abs, ascending=False)\n",
    "    )\n",
    "    print(f\"Top 15 target correlations:\")\n",
    "    for feature, corr in target_corr.head(15).items():\n",
    "        print(f\"  {feature}: {corr:.3f}\")\n",
    "\n",
    "    return corr_matrix\n",
    "\n",
    "\n",
    "corr_matrix = correlation_analysis(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FEATURE ENGINEERING ===\n",
      "✓ Created 5 engineered features\n",
      "New features: ['jitter_stability_ratio', 'shimmer_composite', 'voice_quality_index', 'frequency_range', 'frequency_cv']\n",
      "Correlation of new features with the target:\n",
      "jitter_stability_ratio   -0.435975\n",
      "shimmer_composite         0.360146\n",
      "voice_quality_index      -0.358165\n",
      "frequency_range           0.013754\n",
      "frequency_cv              0.033349\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 4.1-4.6: Feature engineering\n",
    "def engineer_features(df):\n",
    "    \"\"\"Create engineered features\"\"\"\n",
    "    print(\"\\n=== FEATURE ENGINEERING ===\")\n",
    "\n",
    "    df_eng = df.copy()\n",
    "\n",
    "    # Create composite features\n",
    "    df_eng[\"jitter_stability_ratio\"] = df_eng[\"MDVP:Jitter(%)\"] / (\n",
    "        df_eng[\"MDVP:Jitter(Abs)\"] + 1e-8\n",
    "    )\n",
    "    df_eng[\"shimmer_composite\"] = (\n",
    "        df_eng[\"MDVP:Shimmer\"] + df_eng[\"Shimmer:APQ3\"] + df_eng[\"Shimmer:APQ5\"]\n",
    "    ) / 3\n",
    "    df_eng[\"voice_quality_index\"] = df_eng[\"HNR\"] / (df_eng[\"NHR\"] + 1)\n",
    "    df_eng[\"frequency_range\"] = df_eng[\"MDVP:Fhi(Hz)\"] - df_eng[\"MDVP:Flo(Hz)\"]\n",
    "    df_eng[\"frequency_cv\"] = df_eng[\"frequency_range\"] / df_eng[\"MDVP:Fo(Hz)\"]\n",
    "\n",
    "    new_features = [\n",
    "        \"jitter_stability_ratio\",\n",
    "        \"shimmer_composite\",\n",
    "        \"voice_quality_index\",\n",
    "        \"frequency_range\",\n",
    "        \"frequency_cv\",\n",
    "    ]\n",
    "\n",
    "    print(f\"✓ Created {len(new_features)} engineered features\")\n",
    "    \n",
    "    # Print the new features\n",
    "    print(f\"New features: {new_features}\")\n",
    "\n",
    "    # Save engineered dataset\n",
    "    df_eng.to_csv(\"../data/processed/parkinsons_engineered.csv\", index=False)\n",
    "    \n",
    "    # Calculate the correlation of the new features with the target\n",
    "    corr_with_target = df_eng[new_features].corrwith(df_eng[\"status\"])\n",
    "    print(f\"Correlation of new features with the target:\\n{corr_with_target}\")\n",
    "\n",
    "    return df_eng\n",
    "\n",
    "\n",
    "df_engineered = engineer_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DATA PREPARATION WITH LOSO CV ===\n",
      "Total subjects: 195\n",
      "Features: 27\n",
      "Train subjects: 137 (137 samples)\n",
      "Test subjects: 58 (58 samples)\n",
      "Train class distribution: {1: 103, 0: 34}\n",
      "Test class distribution: {1: 44, 0: 14}\n",
      "✓ No subject overlap between train and test sets\n"
     ]
    }
   ],
   "source": [
    "# 5.2: LOSO CV split by name and status stratification\n",
    "def prepare_data_loso(df):\n",
    "    \"\"\"Prepare data with Leave-One-Subject-Out (LOSO) cross-validation setup\"\"\"\n",
    "    print(\"\\n=== DATA PREPARATION WITH LOSO CV ===\")\n",
    "\n",
    "    # Prepare features and target\n",
    "    feature_cols = [col for col in df.columns if col not in [\"name\", \"status\"]]\n",
    "    X = df[feature_cols]\n",
    "    y = df[\"status\"]\n",
    "    names = df[\"name\"]\n",
    "\n",
    "    print(f\"Total subjects: {len(df['name'].unique())}\")\n",
    "    print(f\"Features: {len(feature_cols)}\")\n",
    "\n",
    "    # For demonstration, we'll use stratified split but keep name information\n",
    "    # In practice, LOSO would iterate through each subject as test set\n",
    "\n",
    "    # Create subject-aware stratified split\n",
    "    # Group by subject name to ensure no subject appears in both train and test\n",
    "    unique_subjects = df[\"name\"].unique()\n",
    "    np.random.seed(RANDOM_STATE)\n",
    "    np.random.shuffle(unique_subjects)\n",
    "\n",
    "    # Calculate split point to maintain roughly 70-30 split while respecting subjects\n",
    "    n_test_subjects = max(1, int(len(unique_subjects) * 0.3))\n",
    "    test_subjects = unique_subjects[:n_test_subjects]\n",
    "    train_subjects = unique_subjects[n_test_subjects:]\n",
    "\n",
    "    # Create train/test splits based on subject names\n",
    "    train_mask = df[\"name\"].isin(train_subjects)\n",
    "    test_mask = df[\"name\"].isin(test_subjects)\n",
    "\n",
    "    X_train = X[train_mask]\n",
    "    X_test = X[test_mask]\n",
    "    y_train = y[train_mask]\n",
    "    y_test = y[test_mask]\n",
    "\n",
    "    print(f\"Train subjects: {len(train_subjects)} ({len(X_train)} samples)\")\n",
    "    print(f\"Test subjects: {len(test_subjects)} ({len(X_test)} samples)\")\n",
    "    print(f\"Train class distribution: {pd.Series(y_train).value_counts().to_dict()}\")\n",
    "    print(f\"Test class distribution: {pd.Series(y_test).value_counts().to_dict()}\")\n",
    "\n",
    "    # Verify no subject overlap\n",
    "    train_subject_set = set(df[train_mask][\"name\"].unique())\n",
    "    test_subject_set = set(df[test_mask][\"name\"].unique())\n",
    "    overlap = train_subject_set.intersection(test_subject_set)\n",
    "\n",
    "    if len(overlap) == 0:\n",
    "        print(\"✓ No subject overlap between train and test sets\")\n",
    "    else:\n",
    "        print(f\"⚠ Warning: {len(overlap)} subjects found in both sets: {overlap}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, train_subjects, test_subjects\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test, train_subjects, test_subjects = prepare_data_loso(\n",
    "    df_engineered\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FEATURE SCALING ===\n",
      "✓ Features scaled with RobustScaler\n"
     ]
    }
   ],
   "source": [
    "# 5.3: Scale features\n",
    "def scale_features(X_train, X_test):\n",
    "    \"\"\"Scale features using RobustScaler\"\"\"\n",
    "    print(\"\\n=== FEATURE SCALING ===\")\n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    X_train_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index\n",
    "    )\n",
    "    X_test_scaled = pd.DataFrame(\n",
    "        scaler.transform(X_test), columns=X_test.columns, index=X_test.index\n",
    "    )\n",
    "\n",
    "    print(\"✓ Features scaled with RobustScaler\")\n",
    "    return X_train_scaled, X_test_scaled, scaler\n",
    "\n",
    "\n",
    "\n",
    "X_train_scaled, X_test_scaled, scaler = scale_features(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SMOTE & FEATURE SELECTION ===\n",
      "After SMOTE: {1: 103, 0: 103}\n",
      "✓ Selected 15 consensus features\n",
      "Consensus features: ['shimmer_composite', 'frequency_range', 'voice_quality_index', 'MDVP:Shimmer(dB)', 'NHR', 'MDVP:RAP', 'MDVP:Shimmer', 'MDVP:PPQ', 'MDVP:Fhi(Hz)', 'MDVP:APQ', 'PPE', 'MDVP:Fo(Hz)', 'Shimmer:APQ3', 'spread1', 'Shimmer:DDA']\n",
      "Correlation of consensus features with the target:\n",
      "shimmer_composite      0.488288\n",
      "frequency_range        0.054313\n",
      "voice_quality_index   -0.482157\n",
      "MDVP:Shimmer(dB)       0.478504\n",
      "NHR                    0.300172\n",
      "MDVP:RAP               0.376226\n",
      "MDVP:Shimmer           0.494679\n",
      "MDVP:PPQ               0.402908\n",
      "MDVP:Fhi(Hz)          -0.193859\n",
      "MDVP:APQ               0.483743\n",
      "PPE                    0.628846\n",
      "MDVP:Fo(Hz)           -0.387142\n",
      "Shimmer:APQ3           0.476398\n",
      "spread1                0.646348\n",
      "Shimmer:DDA            0.476367\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 5.4: SMOTE and feature selection\n",
    "def apply_smote_and_feature_selection(X_train, y_train):\n",
    "    \"\"\"Apply SMOTE and feature selection\"\"\"\n",
    "    print(\"\\n=== SMOTE & FEATURE SELECTION ===\")\n",
    "\n",
    "    # SMOTE\n",
    "    smote = SMOTE(random_state=RANDOM_STATE, k_neighbors=3)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    print(f\"After SMOTE: {pd.Series(y_train_smote).value_counts().to_dict()}\")\n",
    "\n",
    "    # Feature selection using multiple methods\n",
    "    feature_selectors = {}\n",
    "\n",
    "    # Statistical selection\n",
    "    selector_stat = SelectKBest(score_func=f_classif, k=15)\n",
    "    selector_stat.fit(X_train, y_train)\n",
    "    selected_stat = X_train.columns[selector_stat.get_support()].tolist()\n",
    "    feature_selectors[\"statistical\"] = selected_stat\n",
    "\n",
    "    # RF importance\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)\n",
    "    rf.fit(X_train, y_train)\n",
    "    importances = pd.Series(rf.feature_importances_, index=X_train.columns)\n",
    "    selected_rf = importances.nlargest(15).index.tolist()\n",
    "    feature_selectors[\"random_forest\"] = selected_rf\n",
    "\n",
    "    # Consensus features (appearing in both methods)\n",
    "    consensus_features = list(set(selected_stat) & set(selected_rf))\n",
    "    if len(consensus_features) < 10:\n",
    "        # If too few consensus features, take top from union\n",
    "        all_selected = list(set(selected_stat + selected_rf))\n",
    "        consensus_features = all_selected[:15]\n",
    "\n",
    "    print(f\"✓ Selected {len(consensus_features)} consensus features\")\n",
    "    print(f\"Consensus features: {consensus_features}\")\n",
    "    \n",
    "    # Calculate the correlation of the new features with the target\n",
    "    corr_with_target = X_train_smote[consensus_features].corrwith(y_train_smote)\n",
    "    print(f\"Correlation of consensus features with the target:\\n{corr_with_target}\")\n",
    "\n",
    "    return X_train_smote, y_train_smote, consensus_features, feature_selectors\n",
    "\n",
    "\n",
    "X_train_smote, y_train_smote, consensus_features, feature_selectors = (\n",
    "    apply_smote_and_feature_selection(X_train_scaled, y_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CREATING DATASET VARIANTS ===\n",
      "✓ Created 5 dataset variants\n",
      "Dataset variants: ['baseline', 'smote', 'feature_selected', 'smote_feature', 'pca']\n"
     ]
    }
   ],
   "source": [
    "# 5.5: Create dataset variants\n",
    "def create_dataset_variants(\n",
    "    X_train, X_test, X_train_smote, y_train, y_train_smote, y_test, consensus_features\n",
    "):\n",
    "    \"\"\"Create different dataset variants for model comparison\"\"\"\n",
    "    print(\"\\n=== CREATING DATASET VARIANTS ===\")\n",
    "\n",
    "    variants = {\n",
    "        \"baseline\": {\n",
    "            \"X_train\": X_train,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_train\": y_train,\n",
    "            \"y_test\": y_test,\n",
    "        },\n",
    "        \"smote\": {\n",
    "            \"X_train\": pd.DataFrame(X_train_smote, columns=X_train.columns),\n",
    "            \"X_test\": X_test,\n",
    "            \"y_train\": pd.Series(y_train_smote),\n",
    "            \"y_test\": y_test,\n",
    "        },\n",
    "        \"feature_selected\": {\n",
    "            \"X_train\": X_train[consensus_features],\n",
    "            \"X_test\": X_test[consensus_features],\n",
    "            \"y_train\": y_train,\n",
    "            \"y_test\": y_test,\n",
    "        },\n",
    "        \"smote_feature\": {\n",
    "            \"X_train\": pd.DataFrame(X_train_smote, columns=X_train.columns)[\n",
    "                consensus_features\n",
    "            ],\n",
    "            \"X_test\": X_test[consensus_features],\n",
    "            \"y_train\": pd.Series(y_train_smote),\n",
    "            \"y_test\": y_test,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # PCA variant\n",
    "    pca = PCA(n_components=0.95, random_state=RANDOM_STATE)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    variants[\"pca\"] = {\n",
    "        \"X_train\": pd.DataFrame(\n",
    "            X_train_pca, columns=[f\"PC{i+1}\" for i in range(X_train_pca.shape[1])]\n",
    "        ),\n",
    "        \"X_test\": pd.DataFrame(\n",
    "            X_test_pca, columns=[f\"PC{i+1}\" for i in range(X_test_pca.shape[1])]\n",
    "        ),\n",
    "        \"y_train\": y_train,\n",
    "        \"y_test\": y_test,\n",
    "    }\n",
    "\n",
    "    print(f\"✓ Created {len(variants)} dataset variants\")\n",
    "    \n",
    "    # Print the name of the dataset variants\n",
    "    print(f\"Dataset variants: {list(variants.keys())}\")\n",
    "\n",
    "    # Save variants\n",
    "    for name, data in variants.items():\n",
    "        data[\"X_train\"].to_csv(f\"../data/processed/X_train_{name}.csv\", index=False)\n",
    "        data[\"X_test\"].to_csv(f\"../data/processed/X_test_{name}.csv\", index=False)\n",
    "        pd.Series(data[\"y_train\"]).to_csv(\n",
    "            f\"../data/processed/y_train_{name}.csv\", index=False, header=[\"status\"]\n",
    "        )\n",
    "        pd.Series(data[\"y_test\"]).to_csv(\n",
    "            f\"../data/processed/y_test_{name}.csv\", index=False, header=[\"status\"]\n",
    "        )\n",
    "\n",
    "    return variants, pca\n",
    "\n",
    "\n",
    "variants, pca = create_dataset_variants(\n",
    "    X_train_scaled,\n",
    "    X_test_scaled,\n",
    "    X_train_smote,\n",
    "    y_train,\n",
    "    y_train_smote,\n",
    "    y_test,\n",
    "    consensus_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MODEL TRAINING ===\n",
      "\n",
      "Training on baseline dataset...\n",
      "  RandomForest: F1=0.946\n",
      "  SVM: F1=0.966\n",
      "  LogisticRegression: F1=0.907\n",
      "  KNN: F1=0.944\n",
      "  DecisionTree: F1=0.909\n",
      "  XGBoost: F1=0.957\n",
      "\n",
      "Training on smote dataset...\n",
      "  RandomForest: F1=0.956\n",
      "  SVM: F1=0.966\n",
      "  LogisticRegression: F1=0.921\n",
      "  KNN: F1=0.929\n",
      "  DecisionTree: F1=0.851\n",
      "  XGBoost: F1=0.956\n",
      "\n",
      "Training on feature_selected dataset...\n",
      "  RandomForest: F1=0.945\n",
      "  SVM: F1=0.955\n",
      "  LogisticRegression: F1=0.921\n",
      "  KNN: F1=0.945\n",
      "  DecisionTree: F1=0.944\n",
      "  XGBoost: F1=0.933\n",
      "\n",
      "Training on smote_feature dataset...\n",
      "  RandomForest: F1=0.956\n",
      "  SVM: F1=0.932\n",
      "  LogisticRegression: F1=0.933\n",
      "  KNN: F1=0.907\n",
      "  DecisionTree: F1=0.884\n",
      "  XGBoost: F1=0.944\n",
      "\n",
      "Training on pca dataset...\n",
      "  RandomForest: F1=0.946\n",
      "  SVM: F1=0.955\n",
      "  LogisticRegression: F1=0.899\n",
      "  KNN: F1=0.933\n",
      "  DecisionTree: F1=0.933\n",
      "  XGBoost: F1=0.936\n"
     ]
    }
   ],
   "source": [
    "# 6.1-6.5: Model training\n",
    "def train_models(variants):\n",
    "    \"\"\"Train multiple models on different dataset variants\"\"\"\n",
    "    print(\"\\n=== MODEL TRAINING ===\")\n",
    "\n",
    "    # Define algorithms\n",
    "    algorithms = {\n",
    "        \"RandomForest\": RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            random_state=RANDOM_STATE,\n",
    "            class_weight=\"balanced\",\n",
    "            n_jobs=5,\n",
    "        ),\n",
    "        \"SVM\": SVC(\n",
    "            random_state=RANDOM_STATE, class_weight=\"balanced\", probability=True\n",
    "        ),\n",
    "        \"LogisticRegression\": LogisticRegression(\n",
    "            random_state=RANDOM_STATE, class_weight=\"balanced\", max_iter=1000\n",
    "        ),\n",
    "        \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "        \"DecisionTree\": DecisionTreeClassifier(\n",
    "            random_state=RANDOM_STATE, class_weight=\"balanced\"\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    algorithms[\"XGBoost\"] = XGBClassifier(\n",
    "        random_state=RANDOM_STATE, eval_metric=\"logloss\", verbosity=0\n",
    "    )\n",
    "\n",
    "    # Hyperparameter grids (simplified for efficiency)\n",
    "    param_grids = {\n",
    "        \"RandomForest\": {\"n_estimators\": [100, 200], \"max_depth\": [10, None]},\n",
    "        \"SVM\": {\"C\": [1, 10], \"kernel\": [\"rbf\", \"linear\"]},\n",
    "        \"LogisticRegression\": {\"C\": [0.1, 1, 10]},\n",
    "        \"KNN\": {\"n_neighbors\": [3, 5, 7]},\n",
    "        \"DecisionTree\": {\"max_depth\": [5, 10, None]},\n",
    "    }\n",
    "\n",
    "    param_grids[\"XGBoost\"] = {\"n_estimators\": [100, 200], \"max_depth\": [3, 5]}\n",
    "\n",
    "    results = []\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "    for variant_name, data in variants.items():\n",
    "        print(f\"\\nTraining on {variant_name} dataset...\")\n",
    "\n",
    "        X_train_var = data[\"X_train\"]\n",
    "        y_train_var = data[\"y_train\"]\n",
    "\n",
    "        for algo_name, model in algorithms.items():\n",
    "            try:\n",
    "                # Grid search\n",
    "                grid_search = GridSearchCV(\n",
    "                    model,\n",
    "                    param_grids.get(algo_name, {}),\n",
    "                    cv=cv,\n",
    "                    scoring=\"f1\",\n",
    "                    n_jobs=5,\n",
    "                    verbose=0,\n",
    "                )\n",
    "\n",
    "                grid_search.fit(X_train_var, y_train_var)\n",
    "\n",
    "                # Test evaluation\n",
    "                X_test_var = data[\"X_test\"]\n",
    "                y_test_var = data[\"y_test\"]\n",
    "                y_pred = grid_search.predict(X_test_var)\n",
    "\n",
    "                # Metrics\n",
    "                metrics = {\n",
    "                    \"algorithm\": algo_name,\n",
    "                    \"dataset\": variant_name,\n",
    "                    \"cv_f1\": grid_search.best_score_,\n",
    "                    \"test_f1\": f1_score(y_test_var, y_pred),\n",
    "                    \"test_accuracy\": accuracy_score(y_test_var, y_pred),\n",
    "                    \"test_precision\": precision_score(\n",
    "                        y_test_var, y_pred, zero_division=0\n",
    "                    ),\n",
    "                    \"test_recall\": recall_score(y_test_var, y_pred),\n",
    "                    \"best_params\": grid_search.best_params_,\n",
    "                    \"model\": grid_search.best_estimator_,\n",
    "                }\n",
    "\n",
    "                results.append(metrics)\n",
    "                print(f\"  {algo_name}: F1={metrics['test_f1']:.3f}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  {algo_name}: Failed - {str(e)[:50]}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "training_results = train_models(variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SELECTING TOP 5 MODELS ===\n",
      "Top models:\n",
      "1. SVM (baseline): F1=0.966\n",
      "2. SVM (smote): F1=0.966\n",
      "3. XGBoost (baseline): F1=0.957\n",
      "4. RandomForest (smote): F1=0.956\n",
      "5. XGBoost (smote): F1=0.956\n"
     ]
    }
   ],
   "source": [
    "# 6.6-6.7: Select top models\n",
    "def select_top_models(results, n_top=5):\n",
    "    \"\"\"Select top performing models\"\"\"\n",
    "    print(f\"\\n=== SELECTING TOP {n_top} MODELS ===\")\n",
    "\n",
    "    # Sort by test F1 score\n",
    "    sorted_results = sorted(results, key=lambda x: x[\"test_f1\"], reverse=True)\n",
    "    top_models = sorted_results[:n_top]\n",
    "\n",
    "    print(\"Top models:\")\n",
    "    for i, model in enumerate(top_models, 1):\n",
    "        print(\n",
    "            f\"{i}. {model['algorithm']} ({model['dataset']}): F1={model['test_f1']:.3f}\"\n",
    "        )\n",
    "\n",
    "    # Save top models\n",
    "    for i, model in enumerate(top_models):\n",
    "        model_name = f\"model_{i+1}_{model['algorithm']}_{model['dataset']}\"\n",
    "        joblib.dump(model[\"model\"], f\"../models/{model_name}.pkl\")\n",
    "\n",
    "    return top_models\n",
    "\n",
    "\n",
    "top_models = select_top_models(training_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MODEL EVALUATION ===\n",
      "   rank     algorithm   dataset  accuracy  precision    recall  specificity  \\\n",
      "0     1           SVM  baseline  0.948276   0.955556  0.977273     0.857143   \n",
      "1     2           SVM     smote  0.948276   0.955556  0.977273     0.857143   \n",
      "2     3       XGBoost  baseline  0.931034   0.916667  1.000000     0.714286   \n",
      "3     4  RandomForest     smote  0.931034   0.934783  0.977273     0.785714   \n",
      "4     5       XGBoost     smote  0.931034   0.934783  0.977273     0.785714   \n",
      "\n",
      "         f1  balanced_accuracy   roc_auc  tn  fp  fn  tp  \n",
      "0  0.966292           0.917208  0.964286  12   2   1  43  \n",
      "1  0.966292           0.917208  0.970779  12   2   1  43  \n",
      "2  0.956522           0.857143  0.957792  10   4   0  44  \n",
      "3  0.955556           0.881494  0.972403  11   3   1  43  \n",
      "4  0.955556           0.881494  0.975649  11   3   1  43  \n"
     ]
    }
   ],
   "source": [
    "# 7.1-7.3: Evaluate top models\n",
    "def evaluate_top_models(top_models, variants):\n",
    "    \"\"\"Comprehensive evaluation of top models\"\"\"\n",
    "    print(\"\\n=== MODEL EVALUATION ===\")\n",
    "\n",
    "    evaluation_results = []\n",
    "\n",
    "    for i, model_info in enumerate(top_models):\n",
    "        algorithm = model_info[\"algorithm\"]\n",
    "        dataset = model_info[\"dataset\"]\n",
    "        model = model_info[\"model\"]\n",
    "\n",
    "        # Get test data\n",
    "        data = variants[dataset]\n",
    "        X_test = data[\"X_test\"]\n",
    "        y_test = data[\"y_test\"]\n",
    "\n",
    "        # Predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = (\n",
    "            model.predict_proba(X_test)[:, 1]\n",
    "            if hasattr(model, \"predict_proba\")\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        # Comprehensive metrics\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "        metrics = {\n",
    "            \"rank\": i + 1,\n",
    "            \"algorithm\": algorithm,\n",
    "            \"dataset\": dataset,\n",
    "            \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "            \"precision\": precision_score(y_test, y_pred, zero_division=0),\n",
    "            \"recall\": recall_score(y_test, y_pred),  # sensitivity\n",
    "            \"specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "            \"f1\": f1_score(y_test, y_pred),\n",
    "            \"balanced_accuracy\": balanced_accuracy_score(y_test, y_pred),\n",
    "            \"roc_auc\": roc_auc_score(y_test, y_proba) if y_proba is not None else None,\n",
    "            \"tn\": tn,\n",
    "            \"fp\": fp,\n",
    "            \"fn\": fn,\n",
    "            \"tp\": tp,\n",
    "        }\n",
    "\n",
    "        evaluation_results.append(metrics)\n",
    "\n",
    "        # Save confusion matrix\n",
    "        cm = np.array([[tn, fp], [fn, tp]])\n",
    "        plt.figure(figsize=(4, 3))\n",
    "        sns.heatmap(\n",
    "            cm,\n",
    "            annot=True,\n",
    "            fmt=\"d\",\n",
    "            cmap=\"Blues\",\n",
    "            xticklabels=[\"Healthy\", \"Parkinson\"],\n",
    "            yticklabels=[\"Healthy\", \"Parkinson\"],\n",
    "        )\n",
    "        plt.title(f\"{algorithm} ({dataset})\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"../figures/confusion_matrix_{algorithm}_{dataset}.png\", dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "    # Save evaluation results\n",
    "    eval_df = pd.DataFrame(evaluation_results)\n",
    "    eval_df.to_csv(\"../results/model_evaluation.csv\", index=False)\n",
    "    \n",
    "    # Print evaluation results\n",
    "    print(eval_df)\n",
    "\n",
    "    return evaluation_results\n",
    "\n",
    "\n",
    "eval_results = evaluate_top_models(top_models, variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL MODEL SELECTION ===\n",
      "Best model: SVM (baseline)\n",
      "F1: 0.966, Accuracy: 0.948\n",
      "Sensitivity: 0.977, Specificity: 0.857\n"
     ]
    }
   ],
   "source": [
    "# 7.4-7.5: Final model selection and saving\n",
    "def select_final_model(eval_results, top_models):\n",
    "    \"\"\"Select and save the final best model\"\"\"\n",
    "    print(\"\\n=== FINAL MODEL SELECTION ===\")\n",
    "\n",
    "    # Best model by F1 score\n",
    "    best_model_info = max(eval_results, key=lambda x: x[\"f1\"])\n",
    "    best_idx = best_model_info[\"rank\"] - 1\n",
    "\n",
    "    print(f\"Best model: {best_model_info['algorithm']} ({best_model_info['dataset']})\")\n",
    "    print(\n",
    "        f\"F1: {best_model_info['f1']:.3f}, Accuracy: {best_model_info['accuracy']:.3f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Sensitivity: {best_model_info['recall']:.3f}, Specificity: {best_model_info['specificity']:.3f}\"\n",
    "    )\n",
    "\n",
    "    # Save final model\n",
    "    final_model = top_models[best_idx][\"model\"]\n",
    "    joblib.dump(final_model, \"../models/final_model.pkl\")\n",
    "\n",
    "    return final_model, best_model_info\n",
    "\n",
    "\n",
    "final_model, best_model_info = select_final_model(eval_results, top_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MODEL EXPLAINABILITY ===\n",
      "\n",
      "--- SHAP Analysis ---\n",
      "Using LinearExplainer/KernelExplainer for non-tree model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:21<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating SHAP visualizations...\n",
      "SHAP values shape: (50, 27)\n",
      "X_explain shape: (50, 27)\n",
      "Feature names length: 27\n",
      "Expected value type: <class 'numpy.float64'>\n",
      "✓ Bar plot saved successfully\n",
      "✓ Detailed plot saved successfully\n",
      "Computing SHAP feature importance...\n",
      "shap_values_pos shape after processing: (50, 27)\n",
      "feature_importance_shap shape: (27,)\n",
      "feature_names length: 27\n",
      "\n",
      "Top 10 features by SHAP importance:\n",
      "  D2: 0.044\n",
      "  spread2: 0.042\n",
      "  Jitter:DDP: 0.030\n",
      "  MDVP:RAP: 0.030\n",
      "  MDVP:Fhi(Hz): 0.022\n",
      "  spread1: 0.021\n",
      "  DFA: 0.021\n",
      "  frequency_cv: 0.020\n",
      "  MDVP:Jitter(%): 0.018\n",
      "  jitter_stability_ratio: 0.017\n",
      "\n",
      "--- Local SHAP Explanations ---\n",
      "Starting local explanations...\n",
      "✓ Parkinson's case waterfall plot saved\n",
      "✓ Healthy case waterfall plot saved\n",
      "Saving SHAP data...\n",
      "✓ SHAP data saved successfully\n",
      "✓ SHAP analysis completed successfully!\n",
      "✓ SHAP visualizations saved to ../figures/\n",
      "✓ SHAP data saved to ../results/\n"
     ]
    }
   ],
   "source": [
    "# 7.6-7.8: Model explainability with comprehensive SHAP analysis\n",
    "def model_explainability(final_model, best_model_info, variants):\n",
    "    \"\"\"Generate comprehensive model explanations using SHAP and feature importance\"\"\"\n",
    "    print(\"\\n=== MODEL EXPLAINABILITY ===\")\n",
    "\n",
    "    dataset = best_model_info[\"dataset\"]\n",
    "    X_test = variants[dataset][\"X_test\"]\n",
    "    X_train = variants[dataset][\"X_train\"]\n",
    "    y_test = variants[dataset][\"y_test\"]\n",
    "\n",
    "    # 1. Traditional Feature Importance (for tree-based models)\n",
    "    if hasattr(final_model, \"feature_importances_\"):\n",
    "        print(\"\\n--- Traditional Feature Importance ---\")\n",
    "        importances = pd.Series(\n",
    "            final_model.feature_importances_, index=X_test.columns\n",
    "        ).sort_values(ascending=False)\n",
    "\n",
    "        print(\"Top 10 feature importances:\")\n",
    "        for feature, importance in importances.head(10).items():\n",
    "            print(f\"  {feature}: {importance:.3f}\")\n",
    "\n",
    "        # Plot feature importance\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        importances.head(15).plot(kind=\"barh\")\n",
    "        plt.title(f'Traditional Feature Importance - {best_model_info[\"algorithm\"]}')\n",
    "        plt.xlabel(\"Importance\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            \"../figures/feature_importance_traditional.png\",\n",
    "            dpi=150,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        plt.close()\n",
    "        print(\"✓ Traditional feature importance saved\")\n",
    "\n",
    "    # 2. SHAP Analysis\n",
    "    try:\n",
    "        import shap\n",
    "\n",
    "        print(\"\\n--- SHAP Analysis ---\")\n",
    "\n",
    "        # Initialize SHAP explainer based on model type\n",
    "        if hasattr(final_model, \"feature_importances_\") and hasattr(\n",
    "            final_model, \"predict_proba\"\n",
    "        ):\n",
    "            # Tree-based models\n",
    "            print(\"Using TreeExplainer for tree-based model...\")\n",
    "            explainer = shap.TreeExplainer(final_model)\n",
    "            X_explain = X_test.sample(\n",
    "                min(100, len(X_test)), random_state=42\n",
    "            )  # Sample for efficiency\n",
    "            shap_values = explainer.shap_values(X_explain)\n",
    "\n",
    "            # For binary classification, use positive class SHAP values\n",
    "            if isinstance(shap_values, list) and len(shap_values) == 2:\n",
    "                shap_values_pos = shap_values[1]  # Positive class (Parkinson's)\n",
    "                expected_value = explainer.expected_value[1]\n",
    "            else:\n",
    "                shap_values_pos = shap_values\n",
    "                expected_value = explainer.expected_value\n",
    "\n",
    "        else:\n",
    "            # Linear models or other models\n",
    "            print(\"Using LinearExplainer/KernelExplainer for non-tree model...\")\n",
    "            if hasattr(final_model, \"coef_\"):\n",
    "                # Linear models\n",
    "                explainer = shap.LinearExplainer(\n",
    "                    final_model, X_train.sample(min(100, len(X_train)), random_state=42)\n",
    "                )\n",
    "            else:\n",
    "                # General kernel explainer (slower)\n",
    "                background = shap.sample(X_train, min(50, len(X_train)))\n",
    "                if hasattr(final_model, \"predict_proba\"):\n",
    "                    explainer = shap.KernelExplainer(\n",
    "                        final_model.predict_proba, background\n",
    "                    )\n",
    "                else:\n",
    "                    explainer = shap.KernelExplainer(final_model.predict, background)\n",
    "\n",
    "            X_explain = X_test.sample(\n",
    "                min(50, len(X_test)), random_state=42\n",
    "            )  # Smaller sample for kernel\n",
    "            shap_values = explainer.shap_values(X_explain)\n",
    "\n",
    "            # Handle binary classification\n",
    "            if isinstance(shap_values, list) and len(shap_values) == 2:\n",
    "                shap_values_pos = shap_values[1]\n",
    "                expected_value = (\n",
    "                    explainer.expected_value[1]\n",
    "                    if hasattr(explainer.expected_value, \"__len__\")\n",
    "                    else explainer.expected_value\n",
    "                )\n",
    "            elif len(shap_values.shape) == 3 and shap_values.shape[2] == 2:\n",
    "                # Handle 3D array from some explainers (shape: n_samples, n_features, n_classes)\n",
    "                shap_values_pos = shap_values[:, :, 1]  # Use positive class\n",
    "                expected_value = (\n",
    "                    explainer.expected_value[1]\n",
    "                    if hasattr(explainer.expected_value, \"__len__\")\n",
    "                    else explainer.expected_value\n",
    "                )\n",
    "            else:\n",
    "                shap_values_pos = shap_values\n",
    "                expected_value = explainer.expected_value\n",
    "\n",
    "        # 3. Generate SHAP Visualizations\n",
    "        print(\"Generating SHAP visualizations...\")\n",
    "\n",
    "        # Convert to numpy arrays and validate data\n",
    "        X_explain_values = X_explain.values\n",
    "        feature_names = X_explain.columns.tolist()\n",
    "\n",
    "        # Debug information\n",
    "        print(f\"SHAP values shape: {shap_values_pos.shape}\")\n",
    "        print(f\"X_explain shape: {X_explain_values.shape}\")\n",
    "        print(f\"Feature names length: {len(feature_names)}\")\n",
    "        print(f\"Expected value type: {type(expected_value)}\")\n",
    "\n",
    "        # Ensure data is clean (no NaN/inf values)\n",
    "        if np.any(np.isnan(shap_values_pos)) or np.any(np.isinf(shap_values_pos)):\n",
    "            print(\"Warning: NaN or inf values found in SHAP values, cleaning...\")\n",
    "            shap_values_pos = np.nan_to_num(\n",
    "                shap_values_pos, nan=0.0, posinf=0.0, neginf=0.0\n",
    "            )\n",
    "\n",
    "        if np.any(np.isnan(X_explain_values)) or np.any(np.isinf(X_explain_values)):\n",
    "            print(\"Warning: NaN or inf values found in X_explain, cleaning...\")\n",
    "            X_explain_values = np.nan_to_num(\n",
    "                X_explain_values, nan=0.0, posinf=0.0, neginf=0.0\n",
    "            )\n",
    "\n",
    "        # Try summary plot with better error handling\n",
    "        try:\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            # Use a simpler approach for summary plot\n",
    "            shap.summary_plot(\n",
    "                shap_values_pos,\n",
    "                X_explain_values,\n",
    "                feature_names=feature_names,\n",
    "                plot_type=\"bar\",\n",
    "                show=False,\n",
    "                max_display=15,\n",
    "            )\n",
    "            plt.title(\"SHAP Feature Importance (Mean |SHAP value|)\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(\"../figures/shap_summary_bar.png\", dpi=150, bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "            print(\"✓ Bar plot saved successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠ Bar plot failed: {str(e)[:100]}\")\n",
    "            plt.close()\n",
    "\n",
    "            # Fallback: Create manual bar plot\n",
    "            try:\n",
    "                feature_importance_shap = np.abs(shap_values_pos).mean(axis=0)\n",
    "                top_indices = np.argsort(feature_importance_shap)[::-1][:15]\n",
    "\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                y_pos = np.arange(len(top_indices))\n",
    "                plt.barh(y_pos, feature_importance_shap[top_indices])\n",
    "                plt.yticks(y_pos, [feature_names[i] for i in top_indices])\n",
    "                plt.xlabel(\"Mean |SHAP value|\")\n",
    "                plt.title(\"SHAP Feature Importance (Manual Plot)\")\n",
    "                plt.gca().invert_yaxis()\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(\n",
    "                    \"../figures/shap_summary_bar.png\", dpi=150, bbox_inches=\"tight\"\n",
    "                )\n",
    "                plt.close()\n",
    "                print(\"✓ Manual bar plot saved successfully\")\n",
    "            except Exception as e2:\n",
    "                print(f\"⚠ Manual bar plot also failed: {str(e2)[:100]}\")\n",
    "                plt.close()\n",
    "\n",
    "        # Try detailed summary plot\n",
    "        try:\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            shap.summary_plot(\n",
    "                shap_values_pos,\n",
    "                X_explain_values,\n",
    "                feature_names=feature_names,\n",
    "                show=False,\n",
    "                max_display=15,\n",
    "            )\n",
    "            plt.title(\"SHAP Summary Plot (Feature Impact)\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(\n",
    "                \"../figures/shap_summary_detailed.png\", dpi=150, bbox_inches=\"tight\"\n",
    "            )\n",
    "            plt.close()\n",
    "            print(\"✓ Detailed plot saved successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠ Detailed plot failed: {str(e)[:100]}\")\n",
    "            plt.close()\n",
    "\n",
    "        # 4. SHAP Feature Ranking\n",
    "        print(\"Computing SHAP feature importance...\")\n",
    "        print(f\"shap_values_pos shape after processing: {shap_values_pos.shape}\")\n",
    "        feature_importance_shap = np.abs(shap_values_pos).mean(axis=0)\n",
    "        print(f\"feature_importance_shap shape: {feature_importance_shap.shape}\")\n",
    "        print(f\"feature_names length: {len(feature_names)}\")\n",
    "\n",
    "        shap_importance_df = pd.DataFrame(\n",
    "            {\"feature\": feature_names, \"shap_importance\": feature_importance_shap}\n",
    "        ).sort_values(\"shap_importance\", ascending=False)\n",
    "\n",
    "        print(\"\\nTop 10 features by SHAP importance:\")\n",
    "        for _, row in shap_importance_df.head(10).iterrows():\n",
    "            print(f\"  {row['feature']}: {row['shap_importance']:.3f}\")\n",
    "\n",
    "        # 5. Local Explanations (individual predictions)\n",
    "        print(\"\\n--- Local SHAP Explanations ---\")\n",
    "        print(\"Starting local explanations...\")\n",
    "\n",
    "        # Find interesting cases: one correctly classified Parkinson's, one correctly classified Healthy\n",
    "        y_pred_explain = final_model.predict(X_explain)\n",
    "        y_true_explain = y_test.loc[X_explain.index]\n",
    "\n",
    "        # Correctly classified Parkinson's case\n",
    "        parkinson_correct = X_explain.index[\n",
    "            (y_true_explain == 1) & (y_pred_explain == 1)\n",
    "        ]\n",
    "        if len(parkinson_correct) > 0:\n",
    "            try:\n",
    "                idx_parkinson = parkinson_correct[0]\n",
    "                local_idx = list(X_explain.index).index(idx_parkinson)\n",
    "\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                shap.waterfall_plot(\n",
    "                    shap.Explanation(\n",
    "                        values=shap_values_pos[local_idx],\n",
    "                        base_values=expected_value,\n",
    "                        data=X_explain_values[local_idx],\n",
    "                        feature_names=feature_names,\n",
    "                    ),\n",
    "                    max_display=10,\n",
    "                    show=False,\n",
    "                )\n",
    "                plt.title(\"SHAP Explanation - Correctly Classified Parkinson's Case\")\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(\n",
    "                    \"../figures/shap_local_parkinson.png\", dpi=150, bbox_inches=\"tight\"\n",
    "                )\n",
    "                plt.close()\n",
    "                print(\"✓ Parkinson's case waterfall plot saved\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠ Parkinson's waterfall plot failed: {str(e)[:100]}\")\n",
    "                plt.close()\n",
    "\n",
    "        # Correctly classified Healthy case\n",
    "        healthy_correct = X_explain.index[(y_true_explain == 0) & (y_pred_explain == 0)]\n",
    "        if len(healthy_correct) > 0:\n",
    "            try:\n",
    "                idx_healthy = healthy_correct[0]\n",
    "                local_idx = list(X_explain.index).index(idx_healthy)\n",
    "\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                shap.waterfall_plot(\n",
    "                    shap.Explanation(\n",
    "                        values=shap_values_pos[local_idx],\n",
    "                        base_values=expected_value,\n",
    "                        data=X_explain_values[local_idx],\n",
    "                        feature_names=feature_names,\n",
    "                    ),\n",
    "                    max_display=10,\n",
    "                    show=False,\n",
    "                )\n",
    "                plt.title(\"SHAP Explanation - Correctly Classified Healthy Case\")\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(\n",
    "                    \"../figures/shap_local_healthy.png\", dpi=150, bbox_inches=\"tight\"\n",
    "                )\n",
    "                plt.close()\n",
    "                print(\"✓ Healthy case waterfall plot saved\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠ Healthy waterfall plot failed: {str(e)[:100]}\")\n",
    "                plt.close()\n",
    "\n",
    "        # 6. Save SHAP values for further analysis\n",
    "        print(\"Saving SHAP data...\")\n",
    "        try:\n",
    "            shap_df = pd.DataFrame(shap_values_pos, columns=feature_names)\n",
    "            shap_df.to_csv(\"../results/shap_values.csv\")\n",
    "            shap_importance_df.to_csv(\n",
    "                \"../results/shap_feature_importance.csv\", index=False\n",
    "            )\n",
    "            print(\"✓ SHAP data saved successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠ Error saving SHAP data: {str(e)[:100]}\")\n",
    "\n",
    "        # 7. SHAP vs Traditional Feature Importance Comparison\n",
    "        if hasattr(final_model, \"feature_importances_\"):\n",
    "            # Compare SHAP importance with traditional importance\n",
    "            traditional_imp = pd.Series(\n",
    "                final_model.feature_importances_, index=feature_names\n",
    "            )\n",
    "            comparison_df = pd.DataFrame(\n",
    "                {\n",
    "                    \"feature\": feature_names,\n",
    "                    \"traditional_importance\": traditional_imp.values,\n",
    "                    \"shap_importance\": feature_importance_shap,\n",
    "                }\n",
    "            ).sort_values(\"shap_importance\", ascending=False)\n",
    "\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            x = np.arange(len(comparison_df.head(15)))\n",
    "            width = 0.35\n",
    "\n",
    "            plt.bar(\n",
    "                x - width / 2,\n",
    "                comparison_df.head(15)[\"traditional_importance\"],\n",
    "                width,\n",
    "                label=\"Traditional Importance\",\n",
    "                alpha=0.8,\n",
    "            )\n",
    "            plt.bar(\n",
    "                x + width / 2,\n",
    "                comparison_df.head(15)[\"shap_importance\"],\n",
    "                width,\n",
    "                label=\"SHAP Importance\",\n",
    "                alpha=0.8,\n",
    "            )\n",
    "\n",
    "            plt.xlabel(\"Features\")\n",
    "            plt.ylabel(\"Importance\")\n",
    "            plt.title(\"Traditional vs SHAP Feature Importance Comparison\")\n",
    "            plt.xticks(x, comparison_df.head(15)[\"feature\"], rotation=45, ha=\"right\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(\n",
    "                \"../figures/importance_comparison.png\", dpi=150, bbox_inches=\"tight\"\n",
    "            )\n",
    "            plt.close()\n",
    "\n",
    "            comparison_df.to_csv(\"../results/importance_comparison.csv\", index=False)\n",
    "\n",
    "        print(\"✓ SHAP analysis completed successfully!\")\n",
    "        print(\"✓ SHAP visualizations saved to ../figures/\")\n",
    "        print(\"✓ SHAP data saved to ../results/\")\n",
    "\n",
    "    except ImportError:\n",
    "        print(\n",
    "            \"⚠ SHAP not available - install with 'pip install shap' for advanced explanations\"\n",
    "        )\n",
    "        print(\"  Run: pip install shap\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ SHAP analysis failed: {str(e)[:100]}...\")\n",
    "        print(\"  Continuing with traditional feature importance only\")\n",
    "\n",
    "\n",
    "model_explainability(final_model, best_model_info, variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL SUMMARY ===\n",
      "Models trained: 30\n",
      "Best F1 score: 0.966\n",
      "Best accuracy: 0.948\n",
      "\n",
      "✓ Results saved to ../\n",
      "✓ Pipeline completed successfully!\n",
      "\n",
      "==================================================\n",
      "🎉 PARKINSON'S DISEASE DETECTION PIPELINE COMPLETE\n",
      "==================================================\n",
      "Outputs saved in organized structure:\n",
      "PARKINSON'S PROJECT\n",
      "  ├── 📁 notebooks/     (analysis code)\n",
      "  ├── 📁 data/\n",
      "  │   ├── 📁 raw/       (original data)\n",
      "  │   └── 📁 processed/ (preprocessed datasets)\n",
      "  ├── 📁 models/        (trained models)\n",
      "  ├── 📁 results/       (evaluation results)\n",
      "  └── 📁 figures/       (visualizations)\n"
     ]
    }
   ],
   "source": [
    "# 7.9: Summary and results\n",
    "def create_summary():\n",
    "    \"\"\"Create final summary\"\"\"\n",
    "    print(\"\\n=== FINAL SUMMARY ===\")\n",
    "\n",
    "    # Training summary\n",
    "    training_df = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"algorithm\": r[\"algorithm\"],\n",
    "                \"dataset\": r[\"dataset\"],\n",
    "                \"test_f1\": r[\"test_f1\"],\n",
    "                \"test_accuracy\": r[\"test_accuracy\"],\n",
    "            }\n",
    "            for r in training_results\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(f\"Models trained: {len(training_results)}\")\n",
    "    print(f\"Best F1 score: {training_df['test_f1'].max():.3f}\")\n",
    "    print(f\"Best accuracy: {training_df['test_accuracy'].max():.3f}\")\n",
    "\n",
    "    # Save all results\n",
    "    results_summary = {\n",
    "        \"training_results\": training_results,\n",
    "        \"evaluation_results\": eval_results,\n",
    "        \"best_model_info\": best_model_info,\n",
    "        \"feature_selectors\": feature_selectors,\n",
    "        \"metadata\": {\n",
    "            \"random_state\": RANDOM_STATE,\n",
    "            \"timestamp\": pd.Timestamp.now().isoformat(),\n",
    "            \"n_models_trained\": len(training_results),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    with open(\"../results/summary.json\", \"w\") as f:\n",
    "        # Convert non-serializable objects\n",
    "        summary_clean = results_summary.copy()\n",
    "        summary_clean[\"training_results\"] = [\n",
    "            {k: v for k, v in r.items() if k != \"model\"} for r in training_results\n",
    "        ]\n",
    "        json.dump(summary_clean, f, indent=2, default=str)\n",
    "\n",
    "    print(\"\\n✓ Results saved to ../\")\n",
    "    print(\"✓ Pipeline completed successfully!\")\n",
    "\n",
    "\n",
    "create_summary()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"🎉 PARKINSON'S DISEASE DETECTION PIPELINE COMPLETE\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Outputs saved in organized structure:\")\n",
    "print(\"PARKINSON'S PROJECT\")\n",
    "print(\"  ├── 📁 notebooks/     (analysis code)\")\n",
    "print(\"  ├── 📁 data/\")\n",
    "print(\"  │   ├── 📁 raw/       (original data)\")\n",
    "print(\"  │   └── 📁 processed/ (preprocessed datasets)\")\n",
    "print(\"  ├── 📁 models/        (trained models)\")\n",
    "print(\"  ├── 📁 results/       (evaluation results)\")\n",
    "print(\"  └── 📁 figures/       (visualizations)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "university-machine-learning-project-parkinsons-voice-v3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
